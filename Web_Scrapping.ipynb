{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMntY86J7KPJ2ZmiuuTGGAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamkarandeepsingh/PhysicsWallah/blob/main/Web_Scrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
      ],
      "metadata": {
        "id": "YF--xzQSimMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans1. Web scraping is the process of extracting data from websites using software. It can be done with a bot or web crawler that simulates human web surfing or with HTML requests that inform the website code of what data to copy.\n",
        "\n",
        "Web scraping is used for various purposes, such as collecting information for analysis, comparison, or indexing. Some areas where web scraping is used to get data include crawling and indexing websites for search engines, collecting data for market research or competitor analysis, and populating news feeds. Is there anything else you would like to know?"
      ],
      "metadata": {
        "id": "8qIFtnETizcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What are the different methods used for Web Scraping?"
      ],
      "metadata": {
        "id": "-ymu6j9PimSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans2. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular APIs or even creating your own code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have APIs that allow you to access their data in a structured format.\n",
        "\n",
        "Web scraping requires two parts, namely the crawler and the scraper. The crawler is an artificial intelligence algorithm that browses the web to search for the particular data required by following the links across the internet. The scraper, on the other hand, is a specific tool created to extract data from the website.\n",
        "\n",
        "There are also web scraping libraries that provide pre-built functions and tools for web scraping tasks. These libraries simplify the process of navigating web pages, parsing HTML data, and locating elements to extract. Some examples of popular web scraping libraries include Beautiful Soup, Scrapy, Puppeteer, Cheerio and Selenium"
      ],
      "metadata": {
        "id": "-A7B2jS5iz7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What is Beautiful Soup? Why is it used?"
      ],
      "metadata": {
        "id": "fm3OIMqQimYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans3. Beautiful Soup is a Python package used for parsing HTML and XML documents. It creates a parse tree for parsed pages which can be used for web scraping, and pulls data from HTML and XML files. It provides simple methods for navigating, searching, and modifying a parse tree in HTML, XML files. It transforms a complex HTML document into a tree of Python objects, and automatically converts the document to Unicode.\n",
        "\n",
        "This tool not only helps you scrape but also to clean the data."
      ],
      "metadata": {
        "id": "spJbJcgpi0Yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Why is flask used in this Web Scraping project?"
      ],
      "metadata": {
        "id": "OzyESbU_imeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans4. Flask is a micro web framework written in Python. It is often used in web scraping projects to create a simple web interface for the user to interact with the scraped data. Flask can also be used to create an API that serves the scraped data to other applications."
      ],
      "metadata": {
        "id": "T6dYqfIVi0-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
      ],
      "metadata": {
        "id": "vlQyc9YgimkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans5. Two AWS services used in the project were codepipe line and elastic beanstack. Codepipeline was used as a medium to transfer files to beanstack while elastic beanstack was used to host the web application independently on AWS platform."
      ],
      "metadata": {
        "id": "pdH3nkali1lR"
      }
    }
  ]
}